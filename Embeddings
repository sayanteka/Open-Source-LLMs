from PIL import Image
import requests

from transformers import CLIPProcessor, CLIPModel

model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32")
processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")



from PIL import Image
import torch

device = "cuda" if torch.cuda.is_available() else "cpu"

def get_image_features(image_paths):
    images = [Image.open(path).convert("RGB") for path in image_paths]
    inputs = processor(images=images, return_tensors="pt").to(device)
    with torch.no_grad():
        image_features = model.get_image_features(**inputs)
        image_features = image_features / image_features.norm(dim=-1, keepdim=True)
    return image_features

mcafee_logos = get_image_features(["/content/mcafee-removebg-preview.png", "/content/mcafee_ver-removebg-preview.png"])
mcafee_shield_logos = get_image_features(["/content/Screenshot_2025-04-05_212545-removebg-preview.png"])




from PIL import Image

# Load and process the image
user_image = Image.open("/content/user_input_1_nobg.png").convert("RGB")
inputs = processor(images=user_image, return_tensors="pt").to(device)

# Encode using the model
with torch.no_grad():
    user_feature = model.get_image_features(**inputs)
    user_feature = user_feature / user_feature.norm(dim=-1, keepdim=True)




def average_cosine_similarity(user_feat, logo_feats):
    sims = torch.nn.functional.cosine_similarity(user_feat, logo_feats.squeeze(1), dim=-1)
    return sims.mean().item()

scores = {
    "McAfee": average_cosine_similarity(user_feature, mcafee_logos),
    "Shield": average_cosine_similarity(user_feature, mcafee_shield_logos),

}

for company, sim in scores.items():
    print(f"{company} similarity: {sim:.4f}")

predicted_class = max(scores, key=scores.get)
print("Predicted class:", predicted_class)


